---
title: Robots
author: Kerim
layout: post
permalink: /archives/2004/07/18/robots/
categories:
  - Culture
  - Info Tech
---
It is now commonplace, thanks especially to the widespread popularity of the book *Chaos*, that a simple set of rules can produce complex results. But when Isaac Asimov first started writing his Robot stories in the late thirties he was a visionary. He saw his robots, not as Frankenstein monsters who turn against their creator, but as essentially rational creatures, guided by laws which require them to protect human lives; however, as with any laws, there are unintended consequences which result from the <a href="http://www.nytimes.com/2004/07/15/movies/15NOTE.html?ex=1247630400&#038;en=027a94e7e71e537d&#038;ei=5090&#038;partner=rssuserland" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://www.nytimes.com/2004/07/15/movies/15NOTE.html?ex=1247630400&en=027a94e7e71e537d&ei=5090&partner=rssuserland', 'complexity inherent within the system']);" >complexity inherent within the system</a>:

> The robot, for Asimov, was humanly designed and had built-in safeguards. His character, the human robopsychologist Susan Calvin, even asserts that robots differ from people because they are &#8220;essentially decent.&#8221; That belief came from Asimov&#8217;s famous Three Laws of Robotics, which were hard-wired into every robot. (They also appear on screen at the opening of the new film.) The first law guaranteed that a robot could not harm a human being or through inaction allow a human being to come to harm; the second was that a robot had to obey human beings except when doing so would conflict with the first law; and the third was that a robot had to protect itself as long as that did not conflict with the first or second law.
> 
> &#8230; Asimov kept exploring how complex these laws were, how much they depended upon interpretation, and how unpredictable robotic intelligence could become. What if multiple people are being harmed and a robot had to act? What if one person had to be harmed to save another? Such dilemmas could cause robotic confusion and delusion. Asimov said, though, that an underlying logic would allow the difficulties to be sorted out.

Unfortunately, the robots in the new film which bears the same title as Asimov&#8217;s 1950 book seems to bear little resemblance to Asimov&#8217;s robots. Its just another monster-action-flick as far as I can tell from the reviews. But Asimov fans can at least enjoy reading a new blog devoted to Asimov&#8217;s <a href="http://www.asimovlaws.com/" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://www.asimovlaws.com/', 'Three Laws of Robotics']);" >Three Laws of Robotics</a>. (via <a href="http://www.boingboing.net/2004/07/16/i_robot_movie_releas.html" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://www.boingboing.net/2004/07/16/i_robot_movie_releas.html', 'BoingBoing']);" >BoingBoing</a>)

Here is my story about the one time I met the great man himself:

I heard him speak when I was about 12. I was a huge fan. When I was getting his autograph, I told him the titles of all the books of his that I&#8217;d read. He looked at me and said, &#8220;You&#8217;re lucky, I never had such good books to read when I was your age!&#8221;

I just hope they don&#8217;t screw things up so badly when they eventually make a film version of the *Foundation* trilogy&#8230;

